# AWS Serverless Streaming Data Pipeline + Real-Time AI Inference

Este reposit√≥rio cont√©m os artefatos de c√≥digo, notebooks e documenta√ß√£o da arquitetura desenvolvida para a Inicia√ß√£o Cient√≠fica sobre **Processamento de Dados em Nuvem: Batch vs. Streaming**.

O projeto demonstra uma implementa√ß√£o **Serverless** na AWS capaz de ingerir dados em tempo real, process√°-los, realizar infer√™ncia de Machine Learning (predi√ß√£o) e armazenar os resultados para an√°lise posterior.

## üìã Arquitetura

A solu√ß√£o utiliza uma abordagem orientada a eventos, integrando servi√ßos gerenciados da AWS para garantir escalabilidade e baixa lat√™ncia.

![Arquitetura do Projeto](./assets/arquitetura.png)

### Fluxo de Dados

1.  **Ingest√£o:** O cliente (dispositivo/usu√°rio) envia dados via requisi√ß√£o HTTP POST para o **Amazon API Gateway**.
2.  **Streaming:** O API Gateway direciona o registro para o **Amazon Kinesis Data Streams (KDS)**.
3.  **Transporte:** O **Amazon Data Firehose** consome os dados do KDS em tempo real.
4.  **Processamento (ETL):** Antes de salvar, o Firehose invoca uma **AWS Lambda** de transforma√ß√£o.
5.  **Infer√™ncia (IA):** A fun√ß√£o Lambda envia os dados brutos para um endpoint do **Amazon SageMaker AI**.
6.  **Predi√ß√£o:** O modelo treinado retorna a predi√ß√£o (ex: valor estimado).
7.  **Enriquecimento:** A Lambda une o dado original + a predi√ß√£o e retorna ao Firehose.
8.  **Armazenamento:** O Firehose persiste o dado enriquecido (JSON/Parquet) em um Bucket **Amazon S3**.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.9+
* **IaC / Compute:** AWS Lambda, Amazon API Gateway
* **Streaming:** Amazon Kinesis Data Streams, Amazon Data Firehose
* **Machine Learning:** Amazon SageMaker (Scikit-Learn/XGBoost)
* **Storage:** Amazon S3
* **Bibliotecas:** `boto3`, `pandas`, `sagemaker`

---

## üöÄ Como Executar
### 1. Treinamento do Modelo (SageMaker)
Acesse a pasta notebooks/. O arquivo model_training.ipynb cont√©m os passos para:

Carregar o dataset.

Treinar o modelo (ex: Regress√£o Linear).

Fazer o deploy do modelo em um Endpoint do SageMaker.

Nota: Copie o nome do Endpoint gerado, ele ser√° usado na Lambda.

### 2. Configura√ß√£o da Lambda
O c√≥digo fonte est√° em lambda/firehose-sagemaker-data-processing.py. Esta fun√ß√£o deve ser configurada como Transformer no Amazon Data Firehose.

### 3. Provisionamento da Infraestrutura (Console AWS)
Kinesis Data Stream: Crie uma stream provisionada ou on-demand.

API Gateway: Crie uma REST API integrada ao servi√ßo Kinesis (Service Proxy).

Data Firehose: Crie uma stream de entrega.

Source: Kinesis Data Stream.

Transform: Habilite a transforma√ß√£o via Lambda e selecione a fun√ß√£o criada.

Destination: Amazon S3.
